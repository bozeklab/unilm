#!/bin/bash -l


#SBATCH --partition=zmmk-exclusive
#SBATCH --nodes=1
#SBATCH --mem=100G
#SBATCH --gres=gpu:2
#SBATCH --time=24-00:00:00

#SBATCH --job-name=beit
#SBATCH --output=beit.txt

### begin of executable commands
conda activate beit3
TOKENIZER_PATH=model_dir/dall_e_tokenizer_weight/
DATA_PATH=/scratch/pwojcik/images_ihc
OUTPUT_DIR=model_dir/
export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python

python -u run_beit_pretraining.py  --data_path ${DATA_PATH} --output_dir ${OUTPUT_DIR} --num_mask_patches 75   --model beit_base_patch16_448_8k_vocab --discrete_vae_weight_path ${TOKENIZER_PATH}  --batch_size 16 --lr 1.5e-3 --warmup_steps 10000 --epochs 400   --clip_grad 3.0 --drop_path 0.1 --layer_scale_init_value 0.1 --input_size 448 --second_input_size 224
